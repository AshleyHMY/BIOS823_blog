{
  
    
        "post0": {
            "title": "Biostat823 Assigment5",
            "content": "Dive into Deep Learning | Train a deep learning model to classify beetles, cockroaches and dragonflies using these images. Note: Original images from https://www.insectimages.org/index.cfm. Blog about this, and explain how the neural network classified the images using SHapley Additive exPlanations. . by Mengyi Ashley Hu . import PIL from PIL import Image import glob import matplotlib.pyplot as plt import numpy as np import os import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers from tensorflow.keras.models import Sequential . path_train = &#39;train/&#39; train = [f for f in glob.glob(path_train + &quot;*/*.jpg&quot;, recursive=True)] . batch_size = 32 img_height = 180 img_width = 180 . train_ds = tf.keras.utils.image_dataset_from_directory( path_train, validation_split=0.2, subset=&quot;training&quot;, seed=123, image_size=(img_height, img_width), batch_size=batch_size) . Found 1019 files belonging to 3 classes. Using 816 files for training. . val_ds = tf.keras.utils.image_dataset_from_directory( path_train, validation_split=0.2, subset=&quot;validation&quot;, seed=123, image_size=(img_height, img_width), batch_size=batch_size) . Found 1019 files belonging to 3 classes. Using 203 files for validation. . class_names = train_ds.class_names print(class_names) . [&#39;beetles&#39;, &#39;cockroach&#39;, &#39;dragonflies&#39;] . plt.figure(figsize=(10, 10)) for images, labels in train_ds.take(1): for i in range(9): ax = plt.subplot(3, 3, i + 1) plt.imshow(images[i].numpy().astype(&quot;uint8&quot;)) plt.title(class_names[labels[i]]) plt.axis(&quot;off&quot;) . for image_batch, labels_batch in train_ds: print(image_batch.shape) print(labels_batch.shape) break . (32, 180, 180, 3) (32,) . AUTOTUNE = tf.data.AUTOTUNE train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE) val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE) . normalization_layer = layers.Rescaling(1./255) . normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)) image_batch, labels_batch = next(iter(normalized_ds)) first_image = image_batch[0] # Notice the pixel values are now in `[0,1]`. print(np.min(first_image), np.max(first_image)) . 0.0 0.9841199 . data_augmentation = keras.Sequential( [ layers.RandomFlip(&quot;horizontal&quot;, input_shape=(img_height, img_width, 3)), layers.RandomRotation(0.1), layers.RandomZoom(0.1), ] ) . plt.figure(figsize=(10, 10)) for images, _ in train_ds.take(1): for i in range(9): augmented_images = data_augmentation(images) ax = plt.subplot(3, 3, i + 1) plt.imshow(augmented_images[0].numpy().astype(&quot;uint8&quot;)) plt.axis(&quot;off&quot;) . num_classes = 3 model = Sequential([data_augmentation, layers.Rescaling(1./255), layers.Conv2D(16, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Conv2D(32, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Conv2D(64, 3, padding=&#39;same&#39;, activation=&#39;relu&#39;), layers.MaxPooling2D(), layers.Dropout(0.2), layers.Flatten(), layers.Dense(128, activation=&#39;relu&#39;), layers.Dense(num_classes) ]) . model.compile(optimizer=&#39;adam&#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[&#39;accuracy&#39;]) . epochs=15 history = model.fit( train_ds, validation_data=val_ds, epochs=epochs ) . Epoch 1/15 26/26 [==============================] - 11s 405ms/step - loss: 0.9130 - accuracy: 0.6091 - val_loss: 0.6027 - val_accuracy: 0.8079 Epoch 2/15 26/26 [==============================] - 10s 394ms/step - loss: 0.6130 - accuracy: 0.7672 - val_loss: 0.4402 - val_accuracy: 0.8325 Epoch 3/15 26/26 [==============================] - 10s 399ms/step - loss: 0.5314 - accuracy: 0.7941 - val_loss: 0.3951 - val_accuracy: 0.8374 Epoch 4/15 26/26 [==============================] - 10s 402ms/step - loss: 0.4701 - accuracy: 0.8186 - val_loss: 0.3613 - val_accuracy: 0.8621 Epoch 5/15 26/26 [==============================] - 10s 387ms/step - loss: 0.4181 - accuracy: 0.8542 - val_loss: 0.4916 - val_accuracy: 0.7931 Epoch 6/15 26/26 [==============================] - 10s 386ms/step - loss: 0.4096 - accuracy: 0.8309 - val_loss: 0.3949 - val_accuracy: 0.8522 Epoch 7/15 26/26 [==============================] - 10s 389ms/step - loss: 0.3695 - accuracy: 0.8627 - val_loss: 0.3309 - val_accuracy: 0.8768 Epoch 8/15 26/26 [==============================] - 10s 386ms/step - loss: 0.3386 - accuracy: 0.8762 - val_loss: 0.4078 - val_accuracy: 0.8670 Epoch 9/15 26/26 [==============================] - 10s 389ms/step - loss: 0.3177 - accuracy: 0.8738 - val_loss: 0.3348 - val_accuracy: 0.9015 Epoch 10/15 26/26 [==============================] - 10s 392ms/step - loss: 0.2911 - accuracy: 0.8848 - val_loss: 0.3921 - val_accuracy: 0.8768 Epoch 11/15 26/26 [==============================] - 10s 388ms/step - loss: 0.2577 - accuracy: 0.8958 - val_loss: 0.3687 - val_accuracy: 0.8768 Epoch 12/15 26/26 [==============================] - 10s 392ms/step - loss: 0.2586 - accuracy: 0.9007 - val_loss: 0.4039 - val_accuracy: 0.8867 Epoch 13/15 26/26 [==============================] - 10s 401ms/step - loss: 0.2546 - accuracy: 0.9020 - val_loss: 0.3136 - val_accuracy: 0.8916 Epoch 14/15 26/26 [==============================] - 11s 405ms/step - loss: 0.2288 - accuracy: 0.9105 - val_loss: 0.4436 - val_accuracy: 0.8768 Epoch 15/15 26/26 [==============================] - 10s 391ms/step - loss: 0.2065 - accuracy: 0.9240 - val_loss: 0.3032 - val_accuracy: 0.9261 . model.summary() . Model: &#34;sequential_3&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= sequential_2 (Sequential) (None, 180, 180, 3) 0 rescaling_3 (Rescaling) (None, 180, 180, 3) 0 conv2d_6 (Conv2D) (None, 180, 180, 16) 448 max_pooling2d_6 (MaxPooling (None, 90, 90, 16) 0 2D) conv2d_7 (Conv2D) (None, 90, 90, 32) 4640 max_pooling2d_7 (MaxPooling (None, 45, 45, 32) 0 2D) conv2d_8 (Conv2D) (None, 45, 45, 64) 18496 max_pooling2d_8 (MaxPooling (None, 22, 22, 64) 0 2D) dropout_2 (Dropout) (None, 22, 22, 64) 0 flatten_2 (Flatten) (None, 30976) 0 dense_4 (Dense) (None, 128) 3965056 dense_5 (Dense) (None, 3) 387 ================================================================= Total params: 3,989,027 Trainable params: 3,989,027 Non-trainable params: 0 _________________________________________________________________ . visualization of training results by train dataset and validation dataset . acc = history.history[&#39;accuracy&#39;] val_acc = history.history[&#39;val_accuracy&#39;] loss = history.history[&#39;loss&#39;] val_loss = history.history[&#39;val_loss&#39;] epochs_range = range(epochs) plt.figure(figsize=(8, 8)) plt.subplot(1, 2, 1) plt.plot(epochs_range, acc, label=&#39;Training Accuracy&#39;) plt.plot(epochs_range, val_acc, label=&#39;Validation Accuracy&#39;) plt.legend(loc=&#39;lower right&#39;) plt.title(&#39;Training and Validation Accuracy&#39;) plt.subplot(1, 2, 2) plt.plot(epochs_range, loss, label=&#39;Training Loss&#39;) plt.plot(epochs_range, val_loss, label=&#39;Validation Loss&#39;) plt.legend(loc=&#39;upper right&#39;) plt.title(&#39;Training and Validation Loss&#39;) plt.show() . predict on new data . import matplotlib.pyplot as plt import matplotlib.image as mpimg . img = mpimg.imread(&#39;dragonfly.jpg&#39;) plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x7f63d349dd10&gt; . img = tf.keras.utils.load_img( &#39;dragonfly.jpg&#39;, target_size=(img_height, img_width) ) img_array = tf.keras.utils.img_to_array(img) img_array = tf.expand_dims(img_array, 0) # Create a batch predictions = model.predict(img_array) score = tf.nn.softmax(predictions[0]) print(np.argmax(score)) print( &quot;This image most likely belongs to {} with a {:.2f} percent confidence.&quot; .format(class_names[np.argmax(score)], 100 * np.max(score))) . 2 This image most likely belongs to dragonflies with a 100.00 percent confidence. . Use the test set to calculate accuracy . path_test = &#39;test/&#39; test = [f for f in glob.glob(path_test + &quot;*/*.jpg&quot;, recursive=True)] . test_ds = tf.keras.utils.image_dataset_from_directory( path_test, image_size=(img_height, img_width), batch_size=batch_size) . Found 180 files belonging to 3 classes. . predictions = model.predict(test_ds) len(predictions) . 180 . score = tf.nn.softmax(predictions) type(score) . tensorflow.python.framework.ops.EagerTensor . pred_test_label = [] for i in range(180): score = tf.nn.softmax(predictions[i]) class_img = np.argmax(score) pred_test_label.append(class_img) . test_label = np.concatenate([y for x, y in test_ds], axis = 0) . acc = np.sum(np.equal(test_label,pred_test_label))/len(test_label) print(&quot;The accuracy calculated using test data is {}&quot;.format(acc)) . The accuracy calculated using test data is 0.3055555555555556 . . Shapley expanation . import shap . x_train = np.concatenate([x for x, y in train_ds], axis = 0) y_train = np.concatenate([y for x, y in train_ds], axis = 0) . x_test = np.concatenate([x for x, y in test_ds], axis = 0) y_test = np.concatenate([y for x, y in test_ds], axis = 0) . explainer = shap.GradientExplainer(model, x_train) . sv = explainer.shap_values(x_test[:20]) . shap.image_plot([sv[i] for i in range(3)], x_test[:3]) .",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/2021/11/15/823-Assignment5.html",
            "relUrl": "/2021/11/15/823-Assignment5.html",
            "date": " • Nov 15, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Biostat823 Assignment3",
            "content": "Biostat823 assignent3 Ashley Hu . 3. Creating effective visualizations using best practices . Create 3 informative visualizations about malaria using Python in a Jupyter notebook, starting with the data sets at https://github.com/rfordatascience/tidytuesday/tree/master/data/2018/2018-11-13. Where appropriate, make the visualizations interactive. . Note There are many libraries you can use for each task. Choose one library and explain why you chose it in your blog. . This assignment use three dataset namely malaria_deaths.csv, malaria_deaths_age.csv, malaria_inc.scv that give information on death rate for all age group(between 1990 and 2016), the number of death cases grouped by age (between 1990 and 2016) and the incidence of malaria (between 2000 and 2015). I used the plotting library bokeh to generate plot1 and plot2. I used the plotting library matplotlib to generate plot3. . import csv import numpy as np import pandas as pd . pip install pandas-bokeh . Requirement already satisfied: pandas-bokeh in /opt/conda/lib/python3.7/site-packages (0.5.5) Requirement already satisfied: pandas&gt;=0.22.0 in /opt/conda/lib/python3.7/site-packages (from pandas-bokeh) (1.1.0) Requirement already satisfied: bokeh&gt;=2.0 in /opt/conda/lib/python3.7/site-packages (from pandas-bokeh) (2.1.1) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas&gt;=0.22.0-&gt;pandas-bokeh) (2.8.1) Requirement already satisfied: pytz&gt;=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas&gt;=0.22.0-&gt;pandas-bokeh) (2020.1) Requirement already satisfied: numpy&gt;=1.15.4 in /opt/conda/lib/python3.7/site-packages (from pandas&gt;=0.22.0-&gt;pandas-bokeh) (1.19.1) Requirement already satisfied: typing-extensions&gt;=3.7.4 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (3.7.4.2) Requirement already satisfied: PyYAML&gt;=3.10 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (5.3.1) Requirement already satisfied: packaging&gt;=16.8 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (20.4) Requirement already satisfied: Jinja2&gt;=2.7 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (2.11.2) Requirement already satisfied: pillow&gt;=4.0 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (7.2.0) Requirement already satisfied: tornado&gt;=5.1 in /opt/conda/lib/python3.7/site-packages (from bokeh&gt;=2.0-&gt;pandas-bokeh) (6.0.4) Requirement already satisfied: six&gt;=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.22.0-&gt;pandas-bokeh) (1.15.0) Requirement already satisfied: pyparsing&gt;=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging&gt;=16.8-&gt;bokeh&gt;=2.0-&gt;pandas-bokeh) (2.4.7) Requirement already satisfied: MarkupSafe&gt;=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2&gt;=2.7-&gt;bokeh&gt;=2.0-&gt;pandas-bokeh) (1.1.1) Note: you may need to restart the kernel to use updated packages. . import pandas_bokeh from bokeh.io import output_notebook, curdoc from bokeh.plotting import figure, show, output_notebook, output_file from bokeh.layouts import gridplot, row, column from bokeh.models import ColumnDataSource, DataRange1d from bokeh.models.tools import HoverTool from bokeh.transform import factor_cmap from bokeh.palettes import brewer from bokeh.tile_providers import CARTODBPOSITRON, get_provider import ipywidgets as widgets output_notebook() . Loading BokehJS ... death = pd.read_csv(&#39;malaria_deaths.csv&#39;) death = death.rename(columns={&quot;Deaths - Malaria - Sex: Both - Age: Age-standardized (Rate) (per 100,000 people)&quot;:&quot;death_rate&quot;}) # To print the first 5 rows of the malaria_deaths.csv file death.head() . Entity Code Year death_rate . 0 Afghanistan | AFG | 1990 | 6.802930 | . 1 Afghanistan | AFG | 1991 | 6.973494 | . 2 Afghanistan | AFG | 1992 | 6.989882 | . 3 Afghanistan | AFG | 1993 | 7.088983 | . 4 Afghanistan | AFG | 1994 | 7.392472 | . deathage = pd.read_csv(&#39;malaria_deaths_age.csv&#39;) deathage = deathage.rename(columns = {&#39;age_group&#39;:&#39;agegroup&#39;}) #To print the first 5 rows of the malaria_deaths_age.csv deathage.head() . Unnamed: 0 entity code year agegroup deaths . 0 1 | Afghanistan | AFG | 1990 | Under 5 | 184.606435 | . 1 2 | Afghanistan | AFG | 1991 | Under 5 | 191.658193 | . 2 3 | Afghanistan | AFG | 1992 | Under 5 | 197.140197 | . 3 4 | Afghanistan | AFG | 1993 | Under 5 | 207.357753 | . 4 5 | Afghanistan | AFG | 1994 | Under 5 | 226.209363 | . inc = pd.read_csv(&#39;malaria_inc.csv&#39;) inc = inc.rename(columns = {&quot;Incidence of malaria (per 1,000 population at risk) (per 1,000 population at risk)&quot;:&quot;incidence&quot;}) #To print the first 5 rows of the malaria_inc.csv inc.head() . Entity Code Year incidence . 0 Afghanistan | AFG | 2000 | 107.100000 | . 1 Afghanistan | AFG | 2005 | 46.500000 | . 2 Afghanistan | AFG | 2010 | 23.900000 | . 3 Afghanistan | AFG | 2015 | 23.600000 | . 4 Algeria | DZA | 2000 | 0.037746 | . Plot1 . I use bokeh to draw two interactive line plots to represent the incidence and overall death rate of malaria. The bokeh library offers hovertools to show the data at each datapoint by pointing at each dot. It also offer a tool bar where I can zoom-in and zoom-out the plot. . def get_incidence_plot(Country): &quot;&quot;&quot; Country is the input, the input is the name of a country. eg. get_incidence_plot(&#39;China&#39;) &gt;&gt;&gt; The output will be a column of two plots. &quot;&quot;&quot; output_file(&quot;line_incidence.html&quot;) tooltips1 = [ (&#39;Incidence&#39;, &#39;@incidence&#39;), (&#39;Year&#39;, &#39;@Year&#39;) ] df1 = inc.loc[inc[&#39;Entity&#39;]==Country] source1 = ColumnDataSource(df1) p1 = figure(title = &#39;Incidence of Malaria (per 1,000 people at risk)&#39;, width = 600, height = 400) p1.line(x = &#39;Year&#39;, y = &#39;incidence&#39;, source = source1) p1.scatter(x = &#39;Year&#39;, y = &#39;incidence&#39;, source = source1) p1.xaxis.axis_label = &#39;Year&#39; p1.yaxis.axis_label = &#39;Incidence (per 1,000 people at risk)&#39; p1.add_tools(HoverTool(tooltips = tooltips1)) tooltips2 = [ (&#39;Death rate&#39;, &#39;@death_rate&#39;), (&#39;Year&#39;, &#39;@Year&#39;) ] df2 = death.loc[death[&#39;Entity&#39;]==Country] source2 = ColumnDataSource(df2) p2 = figure(title = &#39;Death rate of Malaria all age group (per 100,000 people)&#39;, width = 600, height = 400) p2.line(x = &#39;Year&#39;, y = &#39;death_rate&#39;, source = source2) p2.scatter(x = &#39;Year&#39;, y = &#39;death_rate&#39;, source = source2) p2.xaxis.axis_label = &#39;Year&#39; p2.yaxis.axis_label = &#39;Death rate (per 100,000 people)&#39; p2.add_tools(HoverTool(tooltips = tooltips2)) return show(column(p1,p2)) . widgets.interact(get_incidence_plot, Country = inc[&quot;Entity&quot;].unique()) . &lt;function __main__.get_incidence_plot(Country)&gt; . Plot 2 . I used the bokeh library to plot a stacked line plot to represent the number of deaths by year grouped by age. . def get_age_death_plot(Country): #Get data df1 = deathage.loc[(deathage[&#39;entity&#39;]==Country)] df2 = df1.pivot(index = &#39;year&#39;, columns = &#39;agegroup&#39;, values = &#39;deaths&#39;) data = dict( years = list(deathage[&#39;year&#39;].unique()), g1 = list(df2[&#39;Under 5&#39;]), g2 = list(df2[&#39;14-May&#39;]), g3 = list(df2[&#39;15-49&#39;]), g4 = list(df2[&#39;50-69&#39;]), g5 = list(df2[&#39;70 or older&#39;])) source = ColumnDataSource(data) #Draw the plot output_file(&quot;area_agedeath_grouped.html&quot;) p = figure(width = 700, height = 400, title = &#39;Death cases by age group&#39;, x_axis_label = &#39;Year&#39;, y_axis_label = &#39;Death case&#39;) p.varea_stack([&#39;g1&#39;, &#39;g2&#39;, &#39;g3&#39;, &#39;g4&#39;, &#39;g5&#39;], x=&#39;years&#39;, color = (&#39;lightsalmon&#39;, &#39;salmon&#39;,&#39;indianred&#39;,&#39;crimson&#39;,&#39;firebrick&#39;), legend_label = (&#39;&lt;5&#39;, &#39;6-14&#39;, &#39;15-49&#39;, &#39;50-69&#39;, &#39;&gt;70&#39;), source = source, fill_alpha = 0.9) p.legend.title = &#39;Age&#39; p.legend.location = &#39;top_left&#39; return show(p) . widgets.interact(get_age_death_plot, Country = deathage[&quot;entity&quot;].unique()) . &lt;function __main__.get_age_death_plot(Country)&gt; . Plot3 . I used the matplotlib library to generate a map to show the incidence of malaria between 2000 and 2015. I used the naturalearth shapefile to plot the country shape and use the incidence data to fill in the plot. . import geopandas as gpd import matplotlib.pyplot as plt . world = gpd.read_file(gpd.datasets.get_path(&#39;naturalearth_lowres&#39;)) . def get_incidence_geographical_plot(year): df = inc.loc[inc[&#39;Year&#39;]==year] key = df[&#39;Entity&#39;] gdf = world.merge(df, left_on = world[&#39;name&#39;], right_on = df[&#39;Entity&#39;], how = &#39;outer&#39;) fig, ax = plt.subplots(1, figsize=(12,5)) gdf.plot(column=&#39;incidence&#39;, cmap=&#39;OrRd&#39;, ax=ax, legend=True, legend_kwds={&#39;label&#39;: &quot;Incidence of malaria (per 1,000 population at risk)&quot;, &#39;orientation&#39;: &quot;horizontal&quot;}) . widgets.interact(get_incidence_geographical_plot, year = inc[&#39;Year&#39;].unique()) . &lt;function __main__.get_incidence_geographical_plot(year)&gt; .",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/2021/10/01/Assignment3.html",
            "relUrl": "/2021/10/01/Assignment3.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Biostat823 Assignment2",
            "content": "Number theory and a Google recruitment puzzle . Find the first 10-digit prime in the decimal expansion of 17π. . The first 5 digits in the decimal expansion of π are 14159. The first 4-digit prime in the decimal expansion of π are 4159. You are asked to find the first 10-digit prime in the decimal expansion of 17π. First solve sub-problems (divide and conquer): . Write a function to generate an arbitrary large expansion of a mathematical expression like π. Hint: You can use the standard library decimal or the 3rd party library sympy to do this | Write a function to check if a number is prime. Hint: See Sieve of Eratosthenes | Write a function to generate sliding windows of a specified width from a long iterable (e.g. a string representation of a number) | . Write unit tests for each of these three functions. You are encouraged, but not required, to try test-driven development. . Now use these helper functions to write the function that you need. Write a unit test for this final function, given that the first 10-digit prime in the expansion e is 7427466391. Finally, solve the given problem. . This assignment can be found in my github blog (named as Biostat 823 Assignment2): https://ashleyhmy.github.io/BIOS823_blog/ . import sympy as sym import math import unittest . def num_expansion(expr, args): &quot;&quot;&quot; generate an arbitary large expansion for a scientific expression like pi and e, returns numeric expression. expr is the mathematical expression to be converted eg, expr = sym.exp(1) use the sympy package to get scientific expression for e args is the number of significant numbers required eg, args = 5 Examples to get arbitary expression for e with 5 significant numbers: &gt;&gt;&gt; num_expansion(expr, 5) 2.7183 &quot;&quot;&quot; num = expr.evalf(args) return num . def is_prime(num): &quot;&quot;&quot; Take input num to check if num is a prime, if num is a prime return True, if num is not a prime return False. Example: &gt;&gt;&gt;is_prime(17) False &quot;&quot;&quot; if num&lt;2: return False if num==2: return True if num&gt;2 and num%2 == 0: return False for i in range(3, 1 + math.floor(math.sqrt(num)), 2): if num%i == 0: return False return True . def get_window(seq, digits): &quot;&quot;&quot; seq is the input, a list of numbers win_size is the size of the window Example: seq = [1,2,3,4,5,6] win_size = 2 &gt;&gt;&gt; window(seq, win_size, step) [[1,2], [2,3], [3,4], [4,5], [5,6]] &quot;&quot;&quot; num_of_chunk = int(len(seq)-digits + 1) for i in range(0, num_of_chunk): yield seq[i:i+digits] . class TestFunctions(unittest.TestCase): def test_num_expansion(self): result = pi.evalf(5) self.assertEqual(num_expansion(pi, 5), result) def test_is_prime(self): self.assertEqual(is_prime(17), True) self.assertEqual(is_prime(10), False) def test_window(self): seq = [1,2,3,4] self.assertEqual(list(get_window(seq, 3)), [[1,2,3],[2,3,4]]) if __name__ == &quot;__main__&quot;: unittest.main(argv=[&#39;&#39;], verbosity =2, exit=False) . test_is_prime (__main__.TestFunctions) ... ok test_num_expansion (__main__.TestFunctions) ... ok test_window (__main__.TestFunctions) ... ok - Ran 3 tests in 0.002s OK . def get_first_prime(expr, args, digits): &quot;&quot;&quot; The input expr is the methametical expression that want to be expanded The input args represents how many significant number is required from the methametical expression The input digits represents the number of digits is in the prime Example: &gt;&gt;&gt;get_first_prime(pi, 200, 10) 5926535897 &quot;&quot;&quot; num1 = num_expansion(expr, args) str1 = str(num1) list1 = str1.split(&#39;.&#39;) lst = [&#39;&#39;.join(list1[0:2])] num = lst[0] seq = [int(a) for a in str(num)] windows = list(window(seq, digits)) prime_lst = [] for win in windows: str1 = &#39;&#39;.join(map(str, win)) num_to_check = int(str1) if is_prime(num_to_check) == True: prime_lst.append(num_to_check) prime = prime_lst[0] return prime . class TestFunctions(unittest.TestCase): &#39;&#39;&#39;To check whether the output of get_first_prime() function is equal to 7427466391 &#39;&#39;&#39; def test_get_first_prime(self): expr = sym.exp(1) self.assertEqual(get_first_prime(expr, 200, 10), 7427466391) if __name__ == &quot;__main__&quot;: unittest.main(argv=[&#39;&#39;], verbosity =2, exit=False) . test_get_first_prime (__main__.TestFunctions) ... ok - Ran 1 test in 0.025s OK . get_first_prime(pi*17, 50, 10) print(&quot;The first 10 digit prime of 17 u03C0 is&quot;, get_first_prime(pi*17, 50, 10)) . The first 10 digit prime of 17π is 8649375157 .",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/2021/09/17/823-Assignment2.html",
            "relUrl": "/2021/09/17/823-Assignment2.html",
            "date": " • Sep 17, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Biostat823 Assignment1",
            "content": "Biostat 823 assignment1-math is fun Ashley Hu . This assignment can also be found in my blog named Biostat 823 Assignment1. . The link for github repo is :https://github.com/AshleyHMY/BIOS823_blog . Q1 By listing the first six prime numbers 2,3,5,7,11 and 13, we can see that the 6th prime is 13. What is the 10001st prime number? (answered by 424,641 people) . n = 10001 prime_numbers = [2,3] i = 3 if (0&lt;n&lt;3): print(n, &#39;th prime number is:&#39;, prime_numbers[n-1]) elif(n&gt;2): while(True): i+=1 flag = False for j in range(2, int(i/2)+1): if (i%j==0): # i is not a prime number if i%j==0. Only need to check the first half of i. flag = True break if (flag==False): prime_numbers.append(i) if(len(prime_numbers)==n): break print(n, &#39;th prime number is:&#39;, prime_numbers[n-1]) else: print(&#39;Please enter a valid number&#39;) . 10001 th prime number is: 104743 . Explanation for Q1: In this question I want to find the 10001st prime number let n = 10001. I created a list called prime_numbers that includes the first two prime number 2 and 3. In the first if statement when n=1 the first prime number is 2 and n=2 the second prime number is 3. I added more elements(prime numbers) to the prime_numbers list. Then I want to check if integers greater than 3 is a prime. First let i=4 and I want to check if 4 is a prime using the for loop (for j in range(2, 3). Here I used int(i/2)+1 to reduce calculation (eg, 10=2x5, if 10 can be divded by 2, we can conclude 10 is not a prime, do not need to check if 10 can be divided by 5 again). If 4 can be divided by 2 or 3, flag will be equal to True and 4 will not be added to the prime_numbers list. Then let i=5 and run the for loop (for j in range(2, 3)). 5 cannot be divided by 2 or 3, thus, 5 is a prime number and 5 is the third element in the prime_numbers list. The code will print &quot;3th prime number is 5. let n=10001, the code will give the 10001th prime number. . Q2, The prime 41, can be written as the sum of six consecutive primes: 41=2+3+5+7+11+13 This is the longest sum of consecutive primes that adds to a prime below one-hundred. The longest sum of consecutive primes below one-thousand that adds to aprime, contains 21 terms, and is equal to 953. Which prime below one million can be written as the sum of the most consecutive primes?(Solved by 62,918 people) . import sympy sum=0 num_lst = [] sum_lst = [] prime_sum_lst = [] limit = 1000000 for num in range(1,limit): if sympy.isprime(num) is True: sum+=num num_lst.append(num) sum_lst.append(sum) for sum in sum_lst: if sum&lt;limit: if sympy.isprime(sum)==True: prime_sum_lst.append(sum) max_sum = max(prime_sum_lst) index = sum_lst.index(max_sum)+1 print(&quot;The required answer is :&quot;, max_sum, &#39;contains&#39;, index, &#39;items&#39;) . The required answer is : 958577 contains 536 items . Explanation for Q2: I use the function isprime from numpy. First, I created a list called num_lst that contains all elements below 1,000,000. I select all prime numbers from 1 to 1,000,000. The sum_lst list contains all possible consecutive sum(eg, 2,5,10,17,28,41). The second for loop select all possible sum betlow 1,000,000 that is a prime number. The prime_sum_lst includes elements (eg, 2,5,17,41). Use the mac() function to select the largest element in prime_sum_lst list. Then, use the index function to get position of max_sum in the sum_lst that is equal to the number of elements in this max_sum. . Q3, The smallest number expressible as the sum of a prime square, prime cube, and prime fourth power is 28. In fact, there are exactly four numbers below fifty that can be expressed in such a way: 28 = 2^2 + 2^3 + 2^4 33 = 3^2 + 2^3 + 2^4 How many numbers below fifty million can be expressed as the sum of a prime square, prime cube, and prime fourth power? (solved by 20805 people) . import numpy as np limit = 50000000 max_prime = int(limit**0.5) #All possible prime numbers should be smaller than the square root of fifty million. prime_sum = [] #To get a list of prime numbers below max_prime using for loop for num in range(2, max_prime): if sympy.isprime(num) is True: num_prime.append(num) for prime3 in num_prime: prime_forth_power = prime3**4 if prime_forth_power &gt; limit: break for prime2 in num_prime: prime_third_forth = prime2**3 + prime_forth_power if prime_third_forth &gt; limit: break for prime1 in num_prime: sum_power = prime1**2 + prime_third_forth if sum_power &gt; limit: break prime_sum.append(sum_power) def unique(list): &quot;&quot;&quot;This unique function selects unique elements in the prime_sum list generated from the above for loop&quot;&quot;&quot; x = np.array(list) unique_lst = np.unique(x) return unique_lst result = len(unique(prime_sum)) result . 1097343 . Explanation for Q3: First use an expression num = a^2+b^2+c^2. a should be smaller than the square root of fifty million. If a^2 is greater than fifty million, this number should not be included in the expression. The max_prime is the maximum number that can be included in the expression. The num_prime includes all primes that can be used in the expression. The for loop selects numbers consists of a prime square, a prime cube and a prime fourth for prime numbers between 2 and max_prime. There are duplicate numbers in the prime_sum list. I create a function called unique() to select unique values in the prime_sum list. The &quot;result&quot; represents the number of unique elements int eh prime_sum list. &quot;result&quot; equals to the number of numbers below fifty million that can be expressed as the sum of a prime square, prime cube and prime fourth power. .",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/2021/09/03/823-Assignment1.html",
            "relUrl": "/2021/09/03/823-Assignment1.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ashleyhmy.github.io/BIOS823_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ashleyhmy.github.io/BIOS823_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ashleyhmy.github.io/BIOS823_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}